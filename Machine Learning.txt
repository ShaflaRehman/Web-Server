machine learning (ml) is a branch of artificial intelligence (ai) and computer science that focuses on using data and algorithms to enable ai to imitate the way that humans learn, gradually improving its accuracy.

how does machine learning work?
uc berkeley (link resides outside ibm.com) breaks out the learning system of a machine learning algorithm into three main parts.

a decision process: in general, machine learning algorithms are used to make a prediction or classification. based on some input data, which can be labeled or unlabeled, your algorithm will produce an estimate about a pattern in the data.
an error function: an error function evaluates the prediction of the model. if there are known examples, an error function can make a comparison to assess the accuracy of the model.
a model optimization process: if the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. the algorithm will repeat this iterative “evaluate and optimize” process, updating weights autonomously until a threshold of accuracy has been met.
ebook
unlock competitive advantage with generative ai + ml
explore the benefits of generative ai and ml and learn how to confidently incorporate these technologies into your business.

related content
register for the white paper on ai governance

machine learning versus deep learning versus neural networks
since deep learning and machine learning tend to be used interchangeably, it’s worth noting the nuances between the two. machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. however, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks.

the way in which deep learning and machine learning differ is in how each algorithm learns. "deep" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn’t necessarily require a labeled dataset. the deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. this eliminates some of the human intervention required and enables the use of large amounts of data. you can think of deep learning as "scalable machine learning" as lex fridman notes in this mit lecture (link resides outside ibm.com).

classical, or "non-deep," machine learning is more dependent on human intervention to learn. human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.

neural networks, or artificial neural networks (anns), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. each node, or artificial neuron, connects to another and has an associated weight and threshold. if the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. otherwise, no data is passed along to the next layer of the network by that node. the “deep” in deep learning is just referring to the number of layers in a neural network. a neural network that consists of more than three layers—which would be inclusive of the input and the output—can be considered a deep learning algorithm or a deep neural network. a neural network that only has three layers is just a basic neural network.

deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition.

see the blog post “ai vs. machine learning vs. deep learning vs. neural networks: what’s the difference?” for a closer look at how the different concepts relate.
